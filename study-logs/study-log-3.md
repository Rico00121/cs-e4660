I really enjoy this week's topic. Observability is a technical term I've heard of for a long time, but I never fully understood its value. However, after delving deeper into this topic, I've gained a new understanding of it.

Optimization, Defense, Trust—I think these three words perfectly encompass the entire concept of observability. I believe observability improves system transparency, making it a trustworthy system that meets R3E standards. It also enhances software engineers and technical experts' holistic understanding of the software system, allowing them to gain deeper insights. Overall, I believe it aligns with the DIKW (Data-to-Information-to-Knowledge-to-Wisdom) model in economics. By collecting data throughout the entire chain and performing extraction and transformation operations, we obtain valuable information—the current state of the system. Further analysis of this information generates knowledge—whether the system is experiencing an anomaly, operating properly, or underutilizing computing resources. Finally, based on this knowledge, we connect it all together, ultimately generating intelligence—which areas can be optimized, which problems can be avoided, or how they can be resolved.

On the other hand, building observability into software systems also increases their explainability, or trustworthiness. Quantitative metrics make it easy to numerically evaluate otherwise abstract and difficult-to-explain software systems. Furthermore, the numerical values ​​make reporting on them straightforward. On the one hand, we can assess system performance and identify areas for optimization; on the other hand, we can assess specific performance data (the R3E guarantees during software delivery) and identify discrepancies between the current system and the resulting guarantees provided by the software developer.

Furthermore, the approach to building an observability system also requires careful consideration: choosing a fully automated, full-lifecycle solution or incrementally adding observability metrics based on specific needs. My approach here is to follow Occam's razor: avoid adding entities unless necessary. While manually building metrics may require more time initially, it provides you with the freedom and a high degree of customization based on your needs, which ultimately outweighs the long-term benefits. Furthermore, it's worth noting that data storage plays a crucial role in the entire data collection and observation process. Since observability systems often monitor entire software systems, they may consist of up to 20 microservice components and dozens of virtual machines. Real-time logs, metrics, and trace records generated by requests can require a significant amount of concurrent storage requests, so a well-designed storage strategy is crucial. I agree with the paper "Towards Obsevability Data Management at Scale" that it's best to design a hot-cold tiered strategy, based on the assumption that only recent data is accessed in most cases. In my opinion, both the hot and cold data tiers can be further divided into multiple layers based on time. Cloud service providers like AWS can be leveraged for storage services, as they have already designed multi-tiered cold storage databases.

Finally, the section on AI observability has inspired me. I'm currently working on an LLM-driven resume polishing project, and one of my biggest pain points is how to collect information to evaluate the quality of my AI agent's work. I also have questions about tracking user input and understanding their pain points. For example, I can abstract common questions from the most frequently asked questions, and analyze user behavior. I think this is a common pain point for modern Vibe coding developers, but by increasing the observability of the system, this problem may be solved. I think this may be a direction I can explore specifically.