The R3E concept I learned this week is quite abstract, but through interpreting it from different perspectives in several papers, I've gained some understanding. In my opinion, it can be applied to all software systems and has been proven effective in traditional software systems. I believe its most important value lies in providing a methodology that provides a broad guideline, or dimensions, for measuring the performance of a software system. Based on these dimensions, people can quantify and define it based on actual business scenarios. Based on my past work experience, I believe this methodology plays a crucial role in software delivery, especially in the field of ML. The biggest challenge with ML systems is that they are not 100% accurate; they contain errors. This creates a problem: when software engineers deliver ML systems, our understanding of them can differ from that of our clients. This is where R3E comes in. Before we begin project development, we can follow the R3E principles and define specific numerical values ​​for deliverables. These definitions serve as the final acceptance criteria. Using R3E, we can easily reach consensus with our clients on the delivery results.

I believe that R3E will be understood and defined differently by different people in different fields. In my opinion, robustness means that my system has a certain tolerance for errors and can internally prevent certain errors. For example, in an ML system, abnormal data during the data ingestion phase can be automatically discarded. Resilience means that the system can continue to function normally under certain pressures and eventually recover to its original state. For example, when faced with a large number of concurrent requests, the inference speed of an ML system will decrease, but it will still function normally. When the number of concurrent requests decreases, it will gradually recover, like a rubber band. Elasticity means that when faced with a large number of requests, the system can automatically scale up according to demand and restore its original resource quantity when it is no longer needed. Reliability, I think of it as a rather abstract definition. From my understanding, it describes the confidence level of a system because it is actually a combination of several other aspects. Improving robustness, resilience, and elasticity actually improves the overall reliability of the system.

I also read the paper "R3E - An Approach to Robustness, Reliability, Resilience and Elasticity Engineering for End-to-End Machine Learning Systems," which I found very interesting. As I mentioned, R3E has different definitions for different aspects. It considers every component in the ML process as an R3E object, each of which exposes attributes (metrics) and operations (APIs) to enable monitoring and control. For example, a data collector is a Data Object, an API service is a Service Object, and an ML model is an ML Object. By defining these different objects, you constrain your analysis perspective, as an ML system consists of different components that require different metrics. This approach provides me with a new perspective on how to define R3E: a contract-based perspective, or a constraint-based perspective. This methodology shares a similar mindset to contract-driven testing, except that it operates at different stages and granularity. However, their approach is the same: before actual development begins, we first define our specifications and verify against them during final acceptance. Furthermore, the QoAChain concept mentioned in the paper bears strong resemblance to the concept of chain programming. Both emphasize chained dependencies, but one focuses on programming syntax and execution flow, while the other focuses on system quality and SLA assurance. In my opinion, the significance of this chain is that if upstream requirements aren't met, downstream requirements won't matter; they must be guaranteed from beginning to end. Linking them together clarifies their interdependencies and facilitates R3E metrics for the entire system.

If we apply this concept to my cold chain system, for example, the data contract might require 99% integrity for temperature data, the service contract might require API latency to be ≤ 1s, and the ML contract might require model prediction accuracy to be ≥ 95%. I think defining different R3E objects based on the QoAChain methodology and conducting a small DMEO on the R3E metrics for this system is an interesting direction. However, whether or not to pursue this initiative requires further consideration.