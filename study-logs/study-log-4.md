This class, Rupanya used the example of a paraglider recommender system explaining what hybrid intelligence software is, how it integrates with LLMs, and how confidence is assessed from a multi-continuum perspective. This really helped me understand the concept of Human as a Service. It also helped me understand the role of humans in LLM-powered systems, as well as the benefits and challenges of introducing humans as a service. I believe the most important point is that the introduction of Human as a Service inevitably introduces some (okay, I think it is huge and unacceptable) delays in the transition from human service to software service, which significantly degrades the user experience. However, I believe we can optimize this delay through technical means, such as improving human evaluation process tools to speed up response times. Furthermore, the inclusion of humans will also lead to new evaluation criteria for the R3E standard of the system.

Regarding the question, "In what ways should adversarial testing differ for hybrid human-AI workflows compared to standalone AI models?" I believe that unlike robustness evaluation of standalone AI models, the inclusion of humans in hybrid human-AI workflows requires us to consider human factors, such as human responsibility and attention deficits, when evaluating them. Furthermore, for adversarial input and output examples, standalone AI models only need to evaluate whether the examples affect the accuracy or consistency of the model output. However, for hybrid human-AI workflows, we also need to assess, for example, whether the model's output itself influences human judgment and whether humans can identify biases in the model's output.

Finally, through this class discussion, I gained a new understanding of the use cases for LLM. We have built a comprehensive observability framework for our software systems, collecting various log information, metrics, and events. This, in itself, only captures value, not creates it. The actual value creation occurs when an observer summarizes and generates insights from the existing information. Traditional observability systems require a significant amount of manual effort to review and summarize insights. I believe that in current era, LLM can partially replace this manual work within this system. Of course, as mentioned in class, to ensure the robustness and reliability of the entire system, I believe we still need *Human-in-the-Loop* (*HITL*) to provide some oversight and optimize the results. But in any case, I believe that the implantation of LLM will reduce human work to a certain extent.